{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Extraction & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/paper.pdf\"\n",
    "out_path = \"../data/paper_extract.txt\"\n",
    "with pymupdf.open(path) as doc, open(out_path, \"wb\") as out:\n",
    "  for page in doc:\n",
    "    text = page.get_text()\n",
    "    text = re.sub(r'\\n+', ' ', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "    text = text.encode(\"utf8\")\n",
    "    out.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size=600,\n",
    "  chunk_overlap=100,\n",
    "  length_function=len,\n",
    "  is_separator_regex=False,\n",
    ")\n",
    "\n",
    "with open(out_path) as file:\n",
    "    text = file.read()\n",
    "    texts = text_splitter.create_documents([text])\n",
    "    text_chunks = [doc.page_content for doc in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:00<00:00,  5.98it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(text_chunks, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences indexed: 83\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "\n",
    "d = embeddings.shape[1]\n",
    "\n",
    "index = faiss.IndexFlatL2(d)\n",
    "\n",
    "index.add(embeddings)\n",
    "\n",
    "print(f\"Total sentences indexed: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: General Idea of the document\n",
      "Most similar sentences:\n",
      "1: The Turkish Online Journal of Educational Technology, 10(3), 203-214. [1] It should be noted that the reason for choosing this sample was for convenience since they were accessible to the researcher (Dörnyei, 2007, p. 98-99). [2] It should be noted that in order to ward off potential misunderstandings and to allow the participants to freely elaborate upon their answers, the interviews were conducted in Polish. [3] Both here and throughout the remainder of the paper, the excerpts are translations of the students’ responses by the present author. (Distance: 1.4060250520706177)\n",
      "2: (2001), the notion of autonomy was introduced and popularized in 1981 by Henri Holec in his seminal report for the Council of Europe entitled Autonomy in Foreign Language Learning in which the researcher defined autonomy in the context of language learning as “the ability to take charge of one’s own learning” (Holec, 1981, p. 3). Holec’s idea of autonomy encompasses some components and capacities on the part of language learners (e.g. self-directed learning). For some other authors autonomy also involves “a capacity – for detachment, critical reflection, decision-making, and independent (Distance: 1.4109294414520264)\n"
     ]
    }
   ],
   "source": [
    "query_sentence = \"General Idea of the document\"\n",
    "query_embedding = model.encode([query_sentence])\n",
    "\n",
    "\n",
    "k = 2 \n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "print(f\"Query: {query_sentence}\")\n",
    "\n",
    "print(\"Most similar sentences:\")\n",
    "for i, idx in enumerate(indices[0]):\n",
    "    print(f\"{i + 1}: {text_chunks[idx]} (Distance: {distances[0][i]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
